<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>TKLab Wiki</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on TKLab Wiki</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Aug 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lab Computing Site</title>
      <link>http://localhost:1313/docs/labcomputingsite/labcomputingsite/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/labcomputingsite/</guid>
      <description>Lab Computing Site # For more information on the lab computing site, please visit the TKLAB Computing Site.</description>
    </item>
    <item>
      <title>ASEM</title>
      <link>http://localhost:1313/docs/active-projects/asem/project/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/active-projects/asem/project/</guid>
      <description>Automated Segmentation of cellular substructures in Electron Microscopy (ASEM) # This repository contains the segmentation pipeline described in&#xA;Benjamin Gallusser, Giorgio Maltese, Giuseppe Di Caprio et al. Deep neural network automated segmentation of cellular structures in volume electron microscopy,Journal of Cell Biology, 2022.&#xA;Please cite the publication if you are using this code in your research.&#xA;Our semi-automated annotation tool from the same publication is available at https://github.com/kirchhausenlab/gc_segment.&#xA;Table of Contents # Installation Optional: Download our data Prepare your own data for prediction Prediction Prepare your own ground truth annotations for fine-tuning or training Fine-Tuning Training Installation # This package is written for machines with either a Linux or a MacOS operating system.</description>
    </item>
    <item>
      <title>BioArchive</title>
      <link>http://localhost:1313/docs/active-projects/cryosamba/paper/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/active-projects/cryosamba/paper/</guid>
      <description>CryoSamba: Self-Supervised Cryo-ET Image Denoising # Abstract # Cryogenic electron tomography (cryo-ET) has rapidly advanced as a high-resolution imaging tool for visualizing subcellular structures in 3D with molecular detail. Direct image inspection remains challenging due to inherent low signal-to-noise ratios (SNR). We introduce CryoSamba, a self-supervised deep learning-based model designed for denoising cryo-ET images. CryoSamba enhances single consecutive 2D planes in tomograms by averaging motion-compensated nearby planes through deep learning interpolation, effectively mimicking increased exposure.</description>
    </item>
    <item>
      <title>CryoSamba Main</title>
      <link>http://localhost:1313/docs/active-projects/cryosamba/project/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/active-projects/cryosamba/project/</guid>
      <description>CryoSamba: Self-Supervised Deep Volumetric Denoising for Cryo-Electron Tomography Data # For Hardware Issues please refer to the Nvidia-CUDA section # For Software Issues please refer to the Python section, Using Conda Environment # This repository contains the denoising pipeline described in the following publication:&#xA;Jose Inacio Costa-Filho, Liam Theveny, Marilina de Sautu, Tom Kirchhausen CryoSamba: Self-Supervised Deep Volumetric Denoising for Cryo-Electron Tomography Data&#xA;Please cite this publication if you are using this code in your research.</description>
    </item>
    <item>
      <title>GitHub</title>
      <link>http://localhost:1313/docs/github/github/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/github/github/</guid>
      <description>Kirchhausenlab GitHub # All the code and software developed by the Kirchhausen lab can be found on our GitHub page.&#xA;Note: You will need to be a member of the Kirchhausen lab GitHub organization to access the repositories.</description>
    </item>
    <item>
      <title>NVIDIA GPU and CUDA Setup Guide</title>
      <link>http://localhost:1313/docs/nvidia-cuda/deeplearningsetup/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/nvidia-cuda/deeplearningsetup/</guid>
      <description>Verifying NVIDIA Hardware and CUDA Installation # Check NVIDIA GPU # First, let&amp;rsquo;s verify if your system recognizes the NVIDIA GPU:&#xA;Open a terminal and run:&#xA;lspci | grep -i nvidia This should display information about your NVIDIA GPU.&#xA;Right-click on the Windows Start button and select &amp;ldquo;Device Manager&amp;rdquo;&#xA;Expand the &amp;ldquo;Display adapters&amp;rdquo; section&#xA;You should see your NVIDIA GPU listed here Recent Macs don&amp;rsquo;t use NVIDIA GPUs. For older Macs:</description>
    </item>
    <item>
      <title>Poetry: Python Dependency Management Made Easy</title>
      <link>http://localhost:1313/docs/python/production_poetry/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/python/production_poetry/</guid>
      <description>Poetry # Explanation # Poetry is a tool for dependency management and packaging in Python. It allows you to declare the libraries your project depends on and it will manage (install/update) them for you.&#xA;Poetry uses a file called pyproject.toml to declare your project dependencies. It then creates a virtual environment and installs the specified dependencies in that environment. Poetry also locks the versions of your dependencies to ensure reproducibility.</description>
    </item>
    <item>
      <title>Using Conda Environment</title>
      <link>http://localhost:1313/docs/python/conda_env/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/python/conda_env/</guid>
      <description>Using Conda Environment # Explanation # Conda is a popular package and environment management system that allows you to create and manage isolated environments for different projects. This guide will walk you through the steps of using Conda to create and manage environments.&#xA;Conda works by creating isolated environments that contain their own set of packages and dependencies. This allows you to work on different projects with different requirements without conflicts.</description>
    </item>
    <item>
      <title>Using Python Without Breaking Your Local Machine!</title>
      <link>http://localhost:1313/docs/python/python-virtual-environment/</link>
      <pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/python/python-virtual-environment/</guid>
      <description>Virtual Environment # Explanation # A virtual environment is like a separate workspace for your code. Imagine you have a desk where you do your work, and on that desk, you have different projects spread out. Each project has its own set of tools, materials, and files.&#xA;Similarly, in programming, a virtual environment is a self-contained space where you can work on different projects without them interfering with each other.</description>
    </item>
    <item>
      <title>Access Resources Directly from Off-site with Key-Based SSH</title>
      <link>http://localhost:1313/docs/getstarted/ssh/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/getstarted/ssh/</guid>
      <description>Accessing Resources Off-site with Key-Based SSH # Purpose # When accessing resources from off-site, such as running a Jupyter notebook on tkl1 or tkl3 or exploring data with Neuroglancer, it can be cumbersome to first SSH onto xtal200 and authenticate with 2FA. This guide will show you how to streamline this process by using key-based SSH, allowing you to access applications served by on-site resources in a single SSH step.</description>
    </item>
    <item>
      <title>Detection and Tracking</title>
      <link>http://localhost:1313/docs/labcomputingsite/tracking/detection_and_tracking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/tracking/detection_and_tracking/</guid>
      <description>5. Detection and Tracking # Introduction # The detection and tracking routines are based on methods described in references [1,2].&#xA;Detection:&#xA;The input image is filtered using two separate filters: A detection model to identify pixels with significant signals. A Laplacian-of-Gaussian filter to identify local maxima. Local maxima at significant locations are used to initialize model fitting, which estimates fluorescence signal amplitude, local background, and sub-pixel location [2]. This code is designed for PSF-like particles; intensity estimates are less reliable for extended objects (e.</description>
    </item>
    <item>
      <title>From Scratch(Advanced)</title>
      <link>http://localhost:1313/docs/active-projects/cryosamba/advanced/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/active-projects/cryosamba/advanced/</guid>
      <description>Advanced instructions # Table of Contents # Installation üêç Training Setup Training üõ†Ô∏è Run Training üöÄ Visualization with TensorBoard üìà Inference Setup Inference üõ†Ô∏è Run Inference üöÄ Installation # Open a terminal window and run conda create --name your-env-name python=3.11 -y to create the environment (replace your-env-name with a desired name). Activate the environment with conda activate your-env-name. In the future, you will have to activate the environment anytime you want to use CryoSamba.</description>
    </item>
    <item>
      <title>Getting Started with the TKLAB Compute</title>
      <link>http://localhost:1313/docs/getstarted/gettingstartedattklab/quickstart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/getstarted/gettingstartedattklab/quickstart/</guid>
      <description>Getting Started # Starter Page&#xA;Request Access # Welcome to TKlab. In order to access our online resources, a formal request needs to be filed by Patrick( stock@tklab.hms.harvard.edu) and Catherine( Catherine.Swan@childrens.harvard.edu). You will receive an email with instructions to activate your xtal200 account. You will be able to access the on-site machines in the dreamspace using your network account credentials. Please report any issues with the network in a timely manner contacting SBgrid( help@sbgrid.</description>
    </item>
    <item>
      <title>Lab Computing Site/CARE</title>
      <link>http://localhost:1313/docs/labcomputingsite/care/care/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/care/care/</guid>
      <description>CARE Installation Guide # Overview # The Content-Aware image REstoration (CARE) package is a Python-based routine for data augmentation and image restoration. The following steps outline the installation process and how to set up your environment for running CARE on the lab&amp;rsquo;s GPU machines.&#xA;Installation Steps # Create a Working Directory:&#xA;Open your terminal and create a new folder for CARE.&#xA;cd ~ mkdir care cd care Create and Activate a Conda Environment:</description>
    </item>
    <item>
      <title>LLSM</title>
      <link>http://localhost:1313/docs/labcomputingsite/llsm_ao-lls_mosaic/llsm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/llsm_ao-lls_mosaic/llsm/</guid>
      <description>4. LLSM / AO-LLS (MOSAIC) Deskew # When images are acquired using the Lattice Light Sheet Microscope (LLSM) or the Adaptive Optics - LLS (AO-LLS), from the Multimodal Optical Scope with Advanced Imaging Correction MOSAIC microscope, the orientation of the images are tilted in relation to the sample coverslip. In both microscopes, the excitation (EO) and detection (DO) objectives are at 30 and 60 degree angle towards the sample coverslip, respectively.</description>
    </item>
    <item>
      <title>Neuroglancer</title>
      <link>http://localhost:1313/docs/labcomputingsite/neuroglancer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/neuroglancer/</guid>
      <description>Neuroglancer # Purpose # Neuroglancer is a powerful tool for viewing FIBSEM raw data, as well as labels and predictions generated by deep learning pipelines. Developed by Google, it offers multiple options for visualizing datasets through a web interface, Python API, and command line tools.&#xA;While general usage tutorials are available online, this document will focus on two specific cases:&#xA;Sharing a Neuroglancer link with volumes stored in AWS. Sharing a Neuroglancer link with volumes located on TK computers.</description>
    </item>
    <item>
      <title>Post-tracking Processing</title>
      <link>http://localhost:1313/docs/labcomputingsite/tracking/post-tracking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/tracking/post-tracking/</guid>
      <description>7. Post-tracking Processing # Introduction # In this section, we provide a list of codes developed for post-tracking analysis. The following procedures outline how to back up data from the scratch directory to /nfs/datasync4 and various post-processing techniques applied to the tracked data.&#xA;Data Backup After Processing # Name of the code: transfer_from_scratch_to_datasync.m&#xA;Once the data collected by the LLSMs has been deskewed and stored temporarily on /datasync4/tklab-llsm or /datasync4/AO-llsm, users can begin their processing, which includes detection, tracking, and post-tracking analysis.</description>
    </item>
    <item>
      <title>Remotely Access Machines/Access Compute</title>
      <link>http://localhost:1313/docs/getstarted/remote_access/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/getstarted/remote_access/</guid>
      <description>Access Remote Machines # The TKLAB has 10% of the total compute of Harvard Med with the following severs:&#xA;3 DGXs equipped with 24 Nvidia A100 GPUs, tkl1, tkl2, tkl3, tkl4, Datasync folders with terrabytes of capacity Scratch folders for developers In total having over 800 CPUs and 30 GPUs To access one of the machines, we have the following:&#xA;On the Harvard Ethernet Network: Run the following commands from your terminal ssh username@tkdgx3.</description>
    </item>
    <item>
      <title>SBGrid Wiki</title>
      <link>http://localhost:1313/docs/sbgrid_wiki/sbgrid/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/sbgrid_wiki/sbgrid/</guid>
      <description>SBGrid Wiki # They support many labs, who all use the suite of tools differently. Much of the wiki is dedicated to support for labs that use the SBGrid GUI and program browser, but there is still useful information for our lab When you encounter an IT issue, the best thing to do is create a help ticket by emailing help@sbgrid.org. Nine times of ten, the person responding will be Justin O‚ÄôConnor, who dedicates extra time from his schedule to managing TK Lab computing infrastructure.</description>
    </item>
    <item>
      <title>SLURM for the CPU Cluster</title>
      <link>http://localhost:1313/docs/getstarted/gettingstartedattklab/slurm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/getstarted/gettingstartedattklab/slurm/</guid>
      <description>SLURM for the CPU Cluster # Overview # The Slurm Workload Manager, previously known as Simple Linux Utility for Resource Management (SLURM), is a free and open-source job scheduler for Linux and Unix-like systems. This tool is utilized to run jobs on the CPU cluster, particularly within Matlab. SLURM enables users to allocate exclusive or non-exclusive access to computer nodes for a specified time period, allowing them to perform computational work efficiently.</description>
    </item>
    <item>
      <title>Tracks Visualizer - Matlab</title>
      <link>http://localhost:1313/docs/labcomputingsite/tracking/lab_view/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/tracking/lab_view/</guid>
      <description>8. Tracks Visualizer - Matlab # Introduction # Visualizing 3D data can be challenging, but several tools are available to help browse data and tracks effectively. These tools allow users to view 2D projections of the data in XY, XZ, and YZ planes, facilitating easier analysis of tracked data.&#xA;Tools and Commands # Commands:&#xA;GU_calcImageProjections.m GU_cme3d2dViewer.m Usage:&#xA;Load and Project Data:&#xA;Use the following commands to load the 3D data and calculate the 2D projections:</description>
    </item>
    <item>
      <title>Websites, References, Githubs</title>
      <link>http://localhost:1313/docs/labcomputingsite/references/references/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/docs/labcomputingsite/references/references/</guid>
      <description>References # Jaqaman, K., Loerke, D., Mettlen, M. et al. (2008). Robust single-particle tracking in live-cell time-lapse sequences. Nature Methods, 5, 695‚Äì702. https://doi.org/10.1038/nmeth.1237&#xA;Fran√ßois Aguet, Costin N. Antonescu, Marcel Mettlen, Sandra L. Schmid, Gaudenz Danuser (2013). Advances in Analysis of Low Signal-to-Noise Images Link Dynamin and AP2 to the Functions of an Endocytic Checkpoint. Developmental Cell. https://doi.org/10.1016/j.devcel.2013.06.019&#xA;Roudot, Philippe, Wesley R Legant, Qiongjing Zou, Kevin M Dean, Erik S Welf, Ana F David, Daniel W Gerlich, Reto Fiolka, Eric Betzig, Gaudenz Danuser.</description>
    </item>
  </channel>
</rss>
